{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a80f2b2c-3e4c-4ce3-a977-c822989b3e67",
   "metadata": {},
   "source": [
    "# **Data Acquisition and Preprocessing**\n",
    "\n",
    "## **Introduction**  \n",
    "This notebook is used to **extract** the ML dataset from **pre-processed Earth System Model (ESM) outputs**, perform preprocessing, and save the results to a user-specific path.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80186cf7-27c4-4f0c-8c56-44c90c649b76",
   "metadata": {},
   "source": [
    "# 1. Setup workspace and Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b37add44-d2ae-4e76-bc1a-effea1531dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d42d82f8-8400-459b-890c-f8ebfc9799e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743960831.283977     197 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743960831.290692     197 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743960831.308977     197 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743960831.308997     197 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743960831.309000     197 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743960831.309002     197 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "### standard imports ###\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import gcsfs\n",
    "### Python file with supporting functions ###\n",
    "# standard imports\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "import random\n",
    "pd.set_option('display.max_colwidth',100)\n",
    "\n",
    "cwd=os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "os.chdir(parent_dir)\n",
    "cwd = parent_dir\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Python file with supporting functions\n",
    "import lib.residual_utils as supporting_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9df76f-dfcb-4044-9a7e-c096f121e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the date range to unify the date type ###\n",
    "\n",
    "# Define date range\n",
    "date_range_start = '2004-01-01T00:00:00.000000000'\n",
    "date_range_end = '2023-12-31T00:00:00.000000000'\n",
    "\n",
    "# create date vector, adds 14 days to start & end\n",
    "dates = pd.date_range(start=date_range_start, \n",
    "                      end=date_range_end,freq='MS')\n",
    "\n",
    "\n",
    "init_date = str(dates[0].year) + format(dates[0].month,'02d')\n",
    "fin_date = str(dates[-1].year) + format(dates[-1].month,'02d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f69c8-22f6-4d6c-9ab6-5748f9d4df36",
   "metadata": {},
   "source": [
    "# 2. Data Introduction and Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f765f8-6a87-4dcd-a89f-6829da257b1d",
   "metadata": {},
   "source": [
    "## **Data Sources and Paths**\n",
    "The data for the machine learning model are derived primarily from **pre-processed Earth System Model (ESM) outputs** with supplemental observational constraints where available. \n",
    "\n",
    "The data is stored in a **cloud-based environment**, ensuring efficient access and scalability for the machine learning workflow. Key datasets include:\n",
    "\n",
    "- **Ensemble dir**:\n",
    "  Contains the original data from pre-processed Earth System Model (ESM) outputs. \n",
    "\n",
    "- **Atmospheric xCO₂ Data**: Provides atmospheric CO₂ concentrations from **CMIP6 models**, essential for driving the long-term trends in oceanic pCO₂.\n",
    "\n",
    "- **SOCAT Data (Mask File)**:  Masking file based on **SOCAT pCO₂ observations**, used to sample model data in a way that reflects real-world observational density.\n",
    "\n",
    "- **Topography and Land-Sea Mask**:  \n",
    "  - **GEBCO Topography File**:    Global topographic dataset used to define coastal regions and provide physical constraints for model inputs.\n",
    "  - **Land-Sea Mask File**:  Binary land-sea mask used to restrict predictions to ocean regions only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8418faf5-54d5-415e-92a5-2ad875d79cf1",
   "metadata": {},
   "source": [
    "## Where is this happening? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a655f4-fa0a-4a42-ab1c-acbbb3d1de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### set up for getting files from leap bucket ###\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "\n",
    "### set paths ###\n",
    "\n",
    "### paths for loading: ###\n",
    "# directory of regridded members from notebook 00\n",
    "ensemble_dir = \"gs://leap-persistent/abbysh/pco2_all_members_1982-2023/00_regridded_members\" # path to regridded data\n",
    "\n",
    "# directory of reference zarr files\n",
    "zarr_dir = 'gs://leap-persistent/abbysh/zarr_files_'\n",
    "\n",
    "# atmospheric xco2 file\n",
    "xco2_path = f\"{zarr_dir}/xco2_cmip6_183501-224912_monthstart.zarr\"\n",
    "\n",
    "# socat data file\n",
    "socat_path = f\"{zarr_dir}/socat_mask_feb1982-dec2023.zarr\"\n",
    "\n",
    "# topo and land-sea masks\n",
    "topo_path = f\"{zarr_dir}/GEBCO_2014_1x1_global.zarr\"\n",
    "lsmask_path = f\"{zarr_dir}/lsmask.zarr\"\n",
    "\n",
    "############################################# change this to your username!\n",
    "\n",
    "your_username = 'Mukkke'\n",
    "\n",
    "# where machine learning inputs are saved\n",
    "MLinputs_path = f\"gs://leap-persistent/{your_username}/pco2_residual/post01_xgb_inputs\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1022e3-160e-49e7-8620-83add5264a18",
   "metadata": {},
   "source": [
    "# 3.  Select specific Earth System Models ( Ensemble Members) and members\n",
    "This notebook uses data from multiple Earth System Models (ESMs) included in the Large Ensemble Testbed (LET). The LET originally provides 100 ensemble members across various ESMs, each representing distinct initial conditions. These ensemble members are essential for capturing internal climate variability and evaluating model uncertainty.\n",
    "\n",
    "You can customize the mems_dict variable to include selected members from each ESM. This flexibility enables broader analysis while preserving the notebook’s overall structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec31f06e-b223-46a8-8964-2b55d03f0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "mems_dict = dict()\n",
    "\n",
    "selected_ensembles = ['ACCESS-ESM1-5', 'CanESM5', 'MPI-ESM1-2-LR', 'UKESM1-0-LL']\n",
    "# ensemble_dir = 'leap-persistent/abbysh/pco2_all_members_1982-2023/00_regridded_members'\n",
    "\n",
    "# Get all paths\n",
    "all_paths = fs.ls(ensemble_dir)\n",
    "\n",
    "# Filter paths containing the selected ensemble names\n",
    "filtered_paths = [\n",
    "    path for path in all_paths\n",
    "    if path.split('/')[-1] in selected_ensembles\n",
    "]\n",
    "\n",
    "for ens_path in filtered_paths:             \n",
    "    ens = ens_path.split('/')[-1]\n",
    "    mems = fs.ls(ens_path)\n",
    "    for mem in mems:        \n",
    "        memo = mem.split('/')[-1]\n",
    "        if ens not in mems_dict:\n",
    "            mems_dict[ens] = [memo]\n",
    "        elif ens in mems_dict:\n",
    "            mems_dict[ens].append(memo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e36a5e-a4b9-4bce-83df-8b825d653d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACCESS-ESM1-5': ['member_r5i1p1f1', 'member_r1i1p1f1', 'member_r10i1p1f1', 'member_r31i1p1f1', 'member_r2i1p1f1'], 'CanESM5': ['member_r3i1p2f1', 'member_r2i1p1f1', 'member_r1i1p2f1', 'member_r1i1p1f1', 'member_r6i1p2f1'], 'MPI-ESM1-2-LR': ['member_r12i1p1f1', 'member_r11i1p1f1', 'member_r15i1p1f1', 'member_r22i1p1f1', 'member_r23i1p1f1'], 'UKESM1-0-LL': ['member_r8i1p1f2', 'member_r1i1p1f2', 'member_r3i1p1f2', 'member_r4i1p1f2', 'member_r2i1p1f2']}\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)  # Set seed for reproducibility\n",
    "\n",
    "selected_mems_dict = {}\n",
    "\n",
    "num_members = 5  # Set the number of ensemble members from each ESM\n",
    "\n",
    "for ens, members in mems_dict.items():\n",
    "    if len(members) >= num_members:\n",
    "        selected_mems_dict[ens] = random.sample(members, num_members)  # Select `num_members` random members\n",
    "    else:\n",
    "        selected_mems_dict[ens] = members  # If there are fewer members than `num_members`, select all\n",
    "\n",
    "print(selected_mems_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "883bd38a-5fc4-4f49-859f-16b2fe704e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: leap-persistent/Mukkke/pco2_residual\n"
     ]
    }
   ],
   "source": [
    "# import gcsfs\n",
    "\n",
    "# fs = gcsfs.GCSFileSystem()\n",
    "\n",
    "# MLinputs_path = \"gs://leap-persistent/Mukkke/pco2_residua/\"\n",
    "\n",
    "# files_to_delete = fs.ls(MLinputs_path, detail=False)\n",
    "\n",
    "# for file_path in files_to_delete:\n",
    "#     fs.rm(file_path, recursive=True)\n",
    "#     print(f\"Deleted: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fd8e65-eaa6-4e43-8f7b-de7db6144dc8",
   "metadata": {},
   "source": [
    "## Processing and Saving ESM Data for ML\n",
    "\n",
    "In this step, we extract the required ML data from ESM datasets stored in **Google Cloud Storage (GCS)**. The extracted data is structured into Pandas DataFrames and saved under our **own username-specific workspace** in GCS. This ensures that we have direct access to preprocessed data for ML experiments. This means that even if you exit and re-enter JupyterHub, your data will remain available, eliminating the need for reprocessing.\n",
    "\n",
    "### **Important Note: Run This Only Once**\n",
    "\n",
    "The **data extraction and processing** step needs to be run **only once** per project, unless new data is required. This helps save computational resources and execution time.\n",
    "\n",
    "For each **ensemble member**, the estimated runtime is:\n",
    "- **1.32 minutes** for data retrieval and processing.\n",
    "- **Total estimated time**: **1.32 × (total number of selected members)** min.\n",
    "\n",
    "With a **128GB CPU**, actual runtimes may vary based on system load and selected members, but this serves as a general guideline.\n",
    "\n",
    "### Before Running Again:\n",
    "Before executing the data processing or ML training steps again, **check whether you actually need new data**. If not, avoid redundant computations to optimize resource usage. You can also check the storage under the path constantly to clear redundant usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f49d8c96-db7d-453f-8fa8-4513a1ea9384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making dataframe 0: ('ACCESS-ESM1-5', 'member_r5i1p1f1')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unsupported type for store_like: 'FSMap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaking dataframe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmember_counter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mens,member\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m### uses utility function file to make data into dataframe for ML use\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43msupporting_functions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensemble_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmember\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxco2_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msocat_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtopo_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mlsmask_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m### Save the pandas dataframe to workspace\u001b[39;00m\n\u001b[1;32m     21\u001b[0m supporting_functions\u001b[38;5;241m.\u001b[39msave_clean_data(df, MLinputs_path, ens, member, dates)\n",
      "File \u001b[0;32m~/LEAPCourse-Climate-Pred-Challenges/Project-StarterCodes/Project3-ReconstructPCO2/lib/residual_utils.py:410\u001b[0m, in \u001b[0;36mcreate_inputs\u001b[0;34m(ensemble_dir_head, ens, member, dates, N_time, xco2_path, socat_path, topo_path, lsmask_path, N_batch)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_inputs\u001b[39m(ensemble_dir_head, ens, member, dates, N_time,\n\u001b[1;32m    372\u001b[0m                   xco2_path, socat_path, topo_path, lsmask_path,\n\u001b[1;32m    373\u001b[0m                   N_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m): \u001b[38;5;66;03m#N_batch should be number of months\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    Creates inputs for machine learning in notebook 02.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m     DS, DS_xco2 \u001b[38;5;241m=\u001b[39m \u001b[43mimport_member_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensemble_dir_head\u001b[49m\u001b[43m,\u001b[49m\u001b[43mens\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmember\u001b[49m\u001b[43m,\u001b[49m\u001b[43mxco2_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43msocat_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m     df \u001b[38;5;241m=\u001b[39m DS\u001b[38;5;241m.\u001b[39mto_dataframe()\n\u001b[1;32m    412\u001b[0m     df \u001b[38;5;241m=\u001b[39m create_features(df, N_time, N_batch \u001b[38;5;241m=\u001b[39m N_batch)\n",
      "File \u001b[0;32m~/LEAPCourse-Climate-Pred-Challenges/Project-StarterCodes/Project3-ReconstructPCO2/lib/residual_utils.py:268\u001b[0m, in \u001b[0;36mimport_member_data\u001b[0;34m(ensemble_dir_head, ens, member, xco2_path, socat_path, dates, files_ext)\u001b[0m\n\u001b[1;32m    264\u001b[0m member_path \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mensemble_dir_head\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmember\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiles_ext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    266\u001b[0m chl_clim_path \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mensemble_dir_head\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmember\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/chlclim*.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiles_ext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 268\u001b[0m member_data \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_mfdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgs://\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mmember_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_engine\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msel(time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28mstr\u001b[39m(dates[\u001b[38;5;241m0\u001b[39m]),\u001b[38;5;28mstr\u001b[39m(dates[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])))\n\u001b[1;32m    269\u001b[0m socat_mask_data \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_mfdataset(socat_path, engine\u001b[38;5;241m=\u001b[39mfile_engine)\u001b[38;5;241m.\u001b[39msel(time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28mstr\u001b[39m(dates[\u001b[38;5;241m0\u001b[39m]),\u001b[38;5;28mstr\u001b[39m(dates[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])))\n\u001b[1;32m    270\u001b[0m tmp \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_mfdataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs://\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mchl_clim_path, engine\u001b[38;5;241m=\u001b[39mfile_engine)\u001b[38;5;241m.\u001b[39mchl_clim\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/backends/api.py:1611\u001b[0m, in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001b[0m\n\u001b[1;32m   1608\u001b[0m     open_ \u001b[38;5;241m=\u001b[39m open_dataset\n\u001b[1;32m   1609\u001b[0m     getattr_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m\n\u001b[0;32m-> 1611\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [\u001b[43mopen_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths1d]\n\u001b[1;32m   1612\u001b[0m closers \u001b[38;5;241m=\u001b[39m [getattr_(ds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_close\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[1;32m   1613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/backends/api.py:679\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    668\u001b[0m     decode_cf,\n\u001b[1;32m    669\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    675\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    676\u001b[0m )\n\u001b[1;32m    678\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 679\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    686\u001b[0m     backend_ds,\n\u001b[1;32m    687\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    698\u001b[0m )\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/backends/zarr.py:1564\u001b[0m, in \u001b[0;36mZarrBackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, synchronizer, consolidated, chunk_store, storage_options, zarr_version, zarr_format, store, engine, use_zarr_fill_value_as_mask, cache_members)\u001b[0m\n\u001b[1;32m   1562\u001b[0m filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m store:\n\u001b[0;32m-> 1564\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mZarrStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynchronizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidate_on_close\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_zarr_fill_value_as_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_members\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_members\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1579\u001b[0m store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/backends/zarr.py:703\u001b[0m, in \u001b[0;36mZarrStore.open_group\u001b[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, zarr_version, zarr_format, use_zarr_fill_value_as_mask, write_empty, cache_members)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mopen_group\u001b[39m(\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    696\u001b[0m     cache_members: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    697\u001b[0m ):\n\u001b[1;32m    698\u001b[0m     (\n\u001b[1;32m    699\u001b[0m         zarr_group,\n\u001b[1;32m    700\u001b[0m         consolidate_on_close,\n\u001b[1;32m    701\u001b[0m         close_store_on_close,\n\u001b[1;32m    702\u001b[0m         use_zarr_fill_value_as_mask,\n\u001b[0;32m--> 703\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_open_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynchronizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidate_on_close\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate_on_close\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_zarr_fill_value_as_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_zarr_fill_value_as_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    718\u001b[0m         zarr_group,\n\u001b[1;32m    719\u001b[0m         mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    727\u001b[0m         cache_members,\n\u001b[1;32m    728\u001b[0m     )\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/backends/zarr.py:1761\u001b[0m, in \u001b[0;36m_get_open_params\u001b[0;34m(store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, zarr_version, use_zarr_fill_value_as_mask, zarr_format)\u001b[0m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidated \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1760\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1761\u001b[0m         zarr_group \u001b[38;5;241m=\u001b[39m \u001b[43mzarr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_consolidated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1762\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[1;32m   1763\u001b[0m         \u001b[38;5;66;03m# ValueError in zarr-python 3.x, KeyError in 2.x.\u001b[39;00m\n\u001b[1;32m   1764\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/zarr/api/synchronous.py:212\u001b[0m, in \u001b[0;36mopen_consolidated\u001b[0;34m(use_consolidated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mopen_consolidated\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, use_consolidated: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Group:\n\u001b[1;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    Alias for :func:`open_group` with ``use_consolidated=True``.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Group(\n\u001b[0;32m--> 212\u001b[0m         \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[43masync_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_consolidated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_consolidated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_consolidated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m     )\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/zarr/core/sync.py:142\u001b[0m, in \u001b[0;36msync\u001b[0;34m(coro, loop, timeout)\u001b[0m\n\u001b[1;32m    139\u001b[0m return_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(finished))\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/zarr/core/sync.py:98\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03mAwait a coroutine and return the result of running it. If awaiting the coroutine raises an\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mexception, the exception will be returned.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ex\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/zarr/api/asynchronous.py:346\u001b[0m, in \u001b[0;36mopen_consolidated\u001b[0;34m(use_consolidated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_consolidated \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_consolidated\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen_consolidated\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_consolidated=False\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to bypass consolidated metadata.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    345\u001b[0m     )\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m open_group(\u001b[38;5;241m*\u001b[39margs, use_consolidated\u001b[38;5;241m=\u001b[39muse_consolidated, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/zarr/api/asynchronous.py:800\u001b[0m, in \u001b[0;36mopen_group\u001b[0;34m(store, mode, cache_attrs, synchronizer, path, chunk_store, storage_options, zarr_version, zarr_format, meta_array, attributes, use_consolidated)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk_store \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    798\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_store is not yet implemented\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 800\u001b[0m store_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m make_store_path(store, mode\u001b[38;5;241m=\u001b[39mmode, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, path\u001b[38;5;241m=\u001b[39mpath)\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    803\u001b[0m     attributes \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/zarr/storage/_common.py:316\u001b[0m, in \u001b[0;36mmake_store_path\u001b[0;34m(store_like, path, mode, storage_options)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported type for store_like: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(store_like)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[unreachable]\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    318\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m StorePath\u001b[38;5;241m.\u001b[39mopen(store, path\u001b[38;5;241m=\u001b[39mpath_normalized, mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m storage_options \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m used_storage_options:\n",
      "\u001b[0;31mTypeError\u001b[0m: Unsupported type for store_like: 'FSMap'"
     ]
    }
   ],
   "source": [
    "### creating pandas dataframes out of \"raw\" data to prep for ML ###\n",
    "N_time = len(dates)\n",
    "member_counter = 0 \n",
    "\n",
    "### loop through each ESM\n",
    "for ens, mem_list in selected_mems_dict.items(): \n",
    "\n",
    "    ### loop through each member of that ESM\n",
    "    for member in mem_list:\n",
    "        \n",
    "        print(f'making dataframe {member_counter}: {ens,member}')\n",
    "\n",
    "        ### uses utility function file to make data into dataframe for ML use\n",
    "        df = supporting_functions.create_inputs(ensemble_dir, ens, member, dates, N_time,\n",
    "                                  xco2_path,\n",
    "                                  socat_path,\n",
    "                                  topo_path,\n",
    "                                  lsmask_path)\n",
    "\n",
    "        ### Save the pandas dataframe to workspace\n",
    "        supporting_functions.save_clean_data(df, MLinputs_path, ens, member, dates)\n",
    "        member_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "635a2018-f332-4470-8cd7-b3871e94de21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-ESM1-5 member_r5i1p1f1\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/ACCESS-ESM1-5/member_r5i1p1f1/MLinput_ACCESS-ESM1-5_r5i1p1f1_mon_1x1_200401_202312.pkl\n",
      "ACCESS-ESM1-5 member_r1i1p1f1\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/ACCESS-ESM1-5/member_r1i1p1f1/MLinput_ACCESS-ESM1-5_r1i1p1f1_mon_1x1_200401_202312.pkl\n",
      "ACCESS-ESM1-5 member_r10i1p1f1\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/ACCESS-ESM1-5/member_r10i1p1f1/MLinput_ACCESS-ESM1-5_r10i1p1f1_mon_1x1_200401_202312.pkl\n",
      "ACCESS-ESM1-5 member_r31i1p1f1\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/ACCESS-ESM1-5/member_r31i1p1f1/MLinput_ACCESS-ESM1-5_r31i1p1f1_mon_1x1_200401_202312.pkl\n",
      "ACCESS-ESM1-5 member_r2i1p1f1\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/ACCESS-ESM1-5/member_r2i1p1f1/MLinput_ACCESS-ESM1-5_r2i1p1f1_mon_1x1_200401_202312.pkl\n",
      "CanESM5 member_r3i1p2f1\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/CanESM5/member_r3i1p2f1/MLinput_CanESM5_r3i1p2f1_mon_1x1_200401_202312.pkl\n",
      "CanESM5 member_r2i1p1f1\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/CanESM5/member_r2i1p1f1/MLinput_CanESM5_r2i1p1f1_mon_1x1_200401_202312.pkl\n",
      "CanESM5 member_r1i1p2f1\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/CanESM5/member_r1i1p2f1/MLinput_CanESM5_r1i1p2f1_mon_1x1_200401_202312.pkl\n",
      "CanESM5 member_r1i1p1f1\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/CanESM5/member_r1i1p1f1/MLinput_CanESM5_r1i1p1f1_mon_1x1_200401_202312.pkl\n",
      "CanESM5 member_r6i1p2f1\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/CanESM5/member_r6i1p2f1/MLinput_CanESM5_r6i1p2f1_mon_1x1_200401_202312.pkl\n",
      "MPI-ESM1-2-LR member_r12i1p1f1\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/MPI-ESM1-2-LR/member_r12i1p1f1/MLinput_MPI-ESM1-2-LR_r12i1p1f1_mon_1x1_200401_202312.pkl\n",
      "MPI-ESM1-2-LR member_r11i1p1f1\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/MPI-ESM1-2-LR/member_r11i1p1f1/MLinput_MPI-ESM1-2-LR_r11i1p1f1_mon_1x1_200401_202312.pkl\n",
      "MPI-ESM1-2-LR member_r15i1p1f1\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/MPI-ESM1-2-LR/member_r15i1p1f1/MLinput_MPI-ESM1-2-LR_r15i1p1f1_mon_1x1_200401_202312.pkl\n",
      "MPI-ESM1-2-LR member_r22i1p1f1\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/MPI-ESM1-2-LR/member_r22i1p1f1/MLinput_MPI-ESM1-2-LR_r22i1p1f1_mon_1x1_200401_202312.pkl\n",
      "MPI-ESM1-2-LR member_r23i1p1f1\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/MPI-ESM1-2-LR/member_r23i1p1f1/MLinput_MPI-ESM1-2-LR_r23i1p1f1_mon_1x1_200401_202312.pkl\n",
      "UKESM1-0-LL member_r8i1p1f2\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/UKESM1-0-LL/member_r8i1p1f2/MLinput_UKESM1-0-LL_r8i1p1f2_mon_1x1_200401_202312.pkl\n",
      "UKESM1-0-LL member_r1i1p1f2\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/UKESM1-0-LL/member_r1i1p1f2/MLinput_UKESM1-0-LL_r1i1p1f2_mon_1x1_200401_202312.pkl\n",
      "UKESM1-0-LL member_r3i1p1f2\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/UKESM1-0-LL/member_r3i1p1f2/MLinput_UKESM1-0-LL_r3i1p1f2_mon_1x1_200401_202312.pkl\n",
      "UKESM1-0-LL member_r4i1p1f2\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/UKESM1-0-LL/member_r4i1p1f2/MLinput_UKESM1-0-LL_r4i1p1f2_mon_1x1_200401_202312.pkl\n",
      "UKESM1-0-LL member_r2i1p1f2\n",
      "leap-persistent/Mukkke/pco2_residual/post01_xgb_inputs/UKESM1-0-LL/member_r2i1p1f2/MLinput_UKESM1-0-LL_r2i1p1f2_mon_1x1_200401_202312.pkl\n"
     ]
    }
   ],
   "source": [
    "for ens, mem_list in selected_mems_dict.items():\n",
    "    for member in mem_list:\n",
    "        print(ens, member)\n",
    "        data_dir = f\"{MLinputs_path}/{ens}/{member}\"\n",
    "        files = fs.ls(data_dir)\n",
    "        for file in files:\n",
    "            print(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
